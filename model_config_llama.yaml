semantic_parser:
  model_name: "llama/Meta-Llama-3-1-70B-Instruct-qszz"
  temperature: 0.0
  max_tokens: 512
  top_p: 1.0
  frequency_penalty: 0.0
  presence_penalty: 0.0


response_generator:
  model_name: "llama/Meta-Llama-3-1-70B-Instruct-qszz"
  temperature: 0.0
  max_tokens: 512
  top_p: 1.0
  frequency_penalty: 0.0
  presence_penalty: 0.0
